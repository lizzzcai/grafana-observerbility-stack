prometheusOperator:
  resources: # {}
    limits:
      cpu: 100m
      memory: 128Mi
    requests:
      cpu: 50m
      memory: 64Mi

grafana:
  adminPassword: admin
  ## Configure additional grafana datasources (passed through tpl)
  ## ref: http://docs.grafana.org/administration/provisioning/#datasources
  additionalDataSources: #[]
    - name: Loki
      type: loki
      access: proxy
      basicAuth: false
      basicAuthPassword: loki
      basicAuthUser: loki
      editable: true
      jsonData:
        tlsSkipVerify: true
        derivedFields:
          - datasourceName: Tempo
            matcherRegex: "traceID=(\\w+)"
            name: TraceID
            url: "$${__value.raw}"
            datasourceUid: tempo
      orgId: 1
      uid: loki
      url: http://loki.loki.svc.cluster.local:3100
      version: 1
    - name: Tempo
      type: tempo
      access: proxy
      basicAuth: false
      basicAuthPassword: tempo
      basicAuthUser: tempo
      editable: true
      jsonData:
        tlsSkipVerify: true
      orgId: 1
      uid: tempo
      url: http://tempo.tempo.svc.cluster.local:3100
      version: 1

## Deploy a Prometheus instance
##
prometheus:

  enabled: true

  prometheusSpec:

    serviceMonitorSelectorNilUsesHelmValues: false

    ## ServiceMonitors to be selected for target discovery.
    ## If {}, select all ServiceMonitors
    ##
    serviceMonitorSelector: {}
    ## Example which selects ServiceMonitors with label "prometheus" set to "somelabel"
    # serviceMonitorSelector:
    #   matchLabels:
    #     prometheus: somelabel

    ## Namespaces to be selected for ServiceMonitor discovery.
    ##
    serviceMonitorNamespaceSelector: {}
    ## Example which selects ServiceMonitors in namespaces with label "prometheus" set to "somelabel"
    # serviceMonitorNamespaceSelector:
    #   matchLabels:
    #     prometheus: somelabel

    ## If true, a nil or {} value for prometheus.prometheusSpec.podMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the podmonitors created
    ##
    podMonitorSelectorNilUsesHelmValues: false

    ## PodMonitors to be selected for target discovery.
    ## If {}, select all PodMonitors
    ##
    podMonitorSelector: {}
    ## Example which selects PodMonitors with label "prometheus" set to "somelabel"
    # podMonitorSelector:
    #   matchLabels:
    #     prometheus: somelabel

    ## Namespaces to be selected for PodMonitor discovery.
    ## See https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#namespaceselector for usage
    ##
    podMonitorNamespaceSelector: {}


    ## How long to retain metrics
    ##
    retention: 2d


    ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations
    ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form
    ## as specified in the official Prometheus documentation:
    ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are
    ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility
    ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible
    ## scrape configs are going to break Prometheus after the upgrade.
    ##
    ## The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the
    ## port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes
    ##
    additionalScrapeConfigs: []
  
  additionalRulesForClusterRole: #[]
  #  - apiGroups: [ "" ]
  #    resources:
  #      - nodes/proxy
  #    verbs: [ "get", "list", "watch" ]
    - apiGroups:
        - "extensions"
        - "networking.k8s.io"
      resources:
        - ingresses/status
        - ingresses
      verbs:
        - get
        - list
        - watch
    - nonResourceURLs:
        - "/metrics"
      verbs:
        - get

  additionalServiceMonitors: # []
    - name: "prometheus-oper-istio-controlplane"

      # Additional labels to set used for the ServiceMonitorSelector. Together with standard labels from
      # the chart
      #
      additionalLabels:
        monitoring: istio-controlplane
        release: monitoring-prometheus-operator

      # Service label for use in assembling a job name of the form <label value>-<port>
      # If no label is specified, the service name is used.
      #
      jobLabel: "istio"

      # labels to transfer from the kubernetes service to the target
      #
      targetLabels: [app]

      # labels to transfer from the kubernetes pods to the target
      #
      podTargetLabels: []

      # Label selector for services to which this ServiceMonitor applies
      #
      selector:
        matchExpressions:
          - {key: istio, operator: In, values: [pilot]}
      # Namespaces from which services are selected
      #
      namespaceSelector:
        # Match any namespace
        #
        any: true

        # Explicit list of namespace names to select
        #
        matchNames: []

      # Endpoints of the selected service to be monitored
      #
      endpoints: #[]
        - port: "http-monitoring"
          interval: 30s

  additionalPodMonitors: #[]
    # Name of the PodMonitor to create
    #
    - name: "prometheus-oper-istio-dataplane"

      # Additional labels to set used for the PodMonitorSelector. Together with standard labels from
      # the chart
      #
      additionalLabels: #{}
        monitoring: istio-dataplane
        release: monitoring-prometheus-operator
      # Pod label for use in assembling a job name of the form <label value>-<port>
      # If no label is specified, the pod endpoint name is used.
      #
      jobLabel: "envoy-stats"

      # Label selector for pods to which this PodMonitor applies
      #
      selector: #{}
        matchExpressions:
          - {key: istio-prometheus-ignore, operator: DoesNotExist}

      # PodTargetLabels transfers labels on the Kubernetes Pod onto the target.
      #
      podTargetLabels: {}

      # SampleLimit defines per-scrape limit on number of scraped samples that will be accepted.
      #
      sampleLimit: 0

      # Namespaces from which pods are selected
      #
      namespaceSelector:
        # Match any namespace
        #
        any: true

        # Explicit list of namespace names to select
        #
        matchNames: []

      # Endpoints of the selected pods to be monitored
      # https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#podmetricsendpoint
      #
      podMetricsEndpoints: #[]
        - path: /stats/prometheus
          interval: 30s
          relabelings:
          - action: keep
            sourceLabels: [__meta_kubernetes_pod_container_name]
            regex: "istio-proxy"
          - action: keep
            sourceLabels: [__meta_kubernetes_pod_annotationpresent_prometheus_io_scrape]
          - sourceLabels: [__address__, __meta_kubernetes_pod_annotation_prometheus_io_port]
            action: replace
            regex: ([^:]+)(?::\d+)?;(\d+)
            replacement: $1:$2
            targetLabel: __address__
          - action: labeldrop
            regex: "__meta_kubernetes_pod_label_(.+)"
          - sourceLabels: [__meta_kubernetes_namespace]
            action: replace
            targetLabel: namespace
          - sourceLabels: [__meta_kubernetes_pod_name]
            action: replace
            targetLabel: pod_name